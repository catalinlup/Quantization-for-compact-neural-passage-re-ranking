{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85fd66c2-9e1e-4c98-b4c5-cafcac308756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import faiss\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import ir_datasets\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12ffb07b-6be4-4ab7-8fd5-1802c235b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM=768\n",
    "M=96\n",
    "K=256\n",
    "SAMPLE_SIZE=200000\n",
    "# SAMPLE_SIZE=1000\n",
    "DATASET_PATH='/home/catalinlup/MyWorkspace/MasterThesis/datasets/h5_indices/faiss.msmarco-v1-passage.tct_colbert.h5'\n",
    "INDEX_SAVE_PATH=f'./saved_indices/pq_index_{M}_{K}.faiss'\n",
    "INDEX_SAVE_PATH_FULL=f'./saved_indices_full/pq_index_{M}_{K}.faiss'\n",
    "QUERY_DATASET_PATH='/home/catalinlup/MyWorkspace/MasterThesis/datasets/encoded_test_set_queries/msmarco-test-2020-queries.npy'\n",
    "QIDS_DATASET_PATH='/home/catalinlup/MyWorkspace/MasterThesis/datasets/encoded_test_set_queries/qids_2020.npy'\n",
    "QREL_PATH='msmarco-passage/trec-dl-2020'\n",
    "BATCH_SIZE = 1000\n",
    "TOP_K=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d8eba-8578-49b2-ab69-643b0c626bc9",
   "metadata": {},
   "source": [
    "# Index Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1cc4af5-aec7-4397-8807-d09f0f20cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexPQ(DIM, M, int(math.log2(K)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7656170-5cec-4d73-b0e7-a7fbb577fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_dataset_vectors(dataset: h5py.Dataset, sample_size) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes a random sample from the provided h5 dataset. If the sample size is none, raturns the entire dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    if sample_size == None:\n",
    "        return dataset[:, :]\n",
    "    \n",
    "\n",
    "    random_ids = np.random.choice(dataset.shape[0], size=sample_size, replace=False)\n",
    "    random_ids.sort()\n",
    "\n",
    "    num_batches = math.ceil(random_ids.shape[0] / BATCH_SIZE)\n",
    "\n",
    "    random_samples = []\n",
    "\n",
    "    for bi in trange(num_batches):\n",
    "\n",
    "        index_start = bi * BATCH_SIZE\n",
    "        index_end = min((bi + 1) * BATCH_SIZE, random_ids.shape[0])\n",
    "\n",
    "        random_id_batch = random_ids[index_start:index_end]\n",
    "        random_samples.append(dataset[random_id_batch])\n",
    "\n",
    "    return np.concatenate(random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7630bb5-28d8-4774-9e47-6b07085b381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:14<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sampled\n",
      "Index trained. Time: 833.1374173164368\n"
     ]
    }
   ],
   "source": [
    "# train the index\n",
    "with h5py.File(DATASET_PATH, 'r') as dataset:\n",
    "    training_sample = sample_from_dataset_vectors(dataset['vectors'], SAMPLE_SIZE)\n",
    "\n",
    "    print('Dataset sampled')\n",
    "\n",
    "    time_start = time.time()\n",
    "    index.train(training_sample)\n",
    "    time_end = time.time()\n",
    "\n",
    "print(f'Index trained. Time: {time_end - time_start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508f8005-5529-42d9-aa48-97e086e37f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index\n",
    "from faiss import write_index\n",
    "\n",
    "write_index(index, INDEX_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78be989-730d-493a-bcc7-031c76897109",
   "metadata": {},
   "source": [
    "# Add data to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3790a213-d4c1-469d-bcfe-39fb9ec41c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index\n",
    "from faiss import read_index\n",
    "\n",
    "index = read_index(INDEX_SAVE_PATH)\n",
    "assert index.metric_type == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95dc94da-3469-4fb6-806f-98d291911c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8842/8842 [40:58<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(DATASET_PATH, 'r') as dataset:\n",
    "    num_batches = math.ceil(dataset['vectors'].shape[0] / BATCH_SIZE)\n",
    "\n",
    "    for bi in trange(num_batches):\n",
    "\n",
    "        index_start = bi * BATCH_SIZE\n",
    "        index_end = min((bi + 1) * BATCH_SIZE, dataset['vectors'].shape[0])\n",
    "\n",
    "        batch = dataset['vectors'][index_start:index_end]\n",
    "        index.add(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4283ac8-1fb1-486d-a459-2330de04f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index\n",
    "from faiss import write_index\n",
    "\n",
    "write_index(index, INDEX_SAVE_PATH_FULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf116da-d3ab-4f52-8822-005628762c67",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4138350-1edf-4a4f-b6ce-00a6028faf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8841823\n"
     ]
    }
   ],
   "source": [
    "# load index\n",
    "from faiss import read_index\n",
    "\n",
    "index = read_index(INDEX_SAVE_PATH_FULL)\n",
    "\n",
    "print(index.ntotal)\n",
    "\n",
    "assert index.ntotal == 8841823\n",
    "assert index.metric_type == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b8f2f8e-abad-4d20-ad1e-fa8d090a0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/catalinlup/MyWorkspace/MasterThesis/datasets/encoded_test_set_queries/msmarco-test-2020-queries.npy\n",
      "/home/catalinlup/MyWorkspace/MasterThesis/datasets/encoded_test_set_queries/qids_2020.npy\n"
     ]
    }
   ],
   "source": [
    "# load query dataset\n",
    "query_vectors = np.load(QUERY_DATASET_PATH)\n",
    "qids = np.load(QIDS_DATASET_PATH)\n",
    "\n",
    "print(QUERY_DATASET_PATH)\n",
    "print(QIDS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fcdc344f-9745-4bb0-8cd0-3081cd1adec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:46<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# perform the search and build the runfile\n",
    "\n",
    "run = defaultdict(dict)\n",
    "\n",
    "for i in trange(query_vectors.shape[0]):\n",
    "    query_vector = query_vectors[i]\n",
    "    qid = qids[i]\n",
    "\n",
    "\n",
    "    D, I = index.search(query_vector.reshape((1,query_vector.shape[0])), TOP_K)\n",
    "\n",
    "\n",
    "    for i in range(I.shape[1]):\n",
    "        doc_id = I[0][i]\n",
    "        doc_score = D[0][i]\n",
    "        run[str(qid)][str(doc_id)] = float(doc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60c884ca-a93b-4994-b716-3adaee7faff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the qrel and evaluate the \n",
    "psgs = ir_datasets.load(QREL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "431eaed7-c2ba-439a-bdaa-0378f0f9c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='23849', doc_id='1020327', relevance=2, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "print(next(psgs.qrels_iter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe624d4f-f764-4030-94e1-a0674d4a02d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nDCG@10: 0.5436612068654874,\n",
       " AP(rel=2)@1000: 0.33754363265102855,\n",
       " RR(rel=2)@10: 0.7305555555555556}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ir_measures import calc_aggregate, nDCG, AP, RR\n",
    "\n",
    "METRICS = [nDCG@10, AP(rel=2)@1000, RR(rel=2)@10]\n",
    "\n",
    "calc_aggregate(METRICS, psgs.qrels_iter(), run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591b2c1-ddfb-4219-8f2c-72e314cd7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

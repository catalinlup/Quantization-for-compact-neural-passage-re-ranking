{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm","mount_file_id":"1zzXf9IyYbSO2l8XOuFXdatuARKBvEJoQ","authorship_tag":"ABX9TyNYfG7ddgxlGXejVnnzlGJA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb0dc2baaa114e37bf582c89cf290544":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4aa727089994d1c8b230bd14302e895","IPY_MODEL_b9bdd5af51354e59a616799599671000","IPY_MODEL_430ec2b161da4e159c858b18e0dbfb90"],"layout":"IPY_MODEL_316af84f280348eb86fd9d0df10de3c5"}},"c4aa727089994d1c8b230bd14302e895":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d1381143a04c2f929e6f39fb677812","placeholder":"​","style":"IPY_MODEL_598519dce71146d4aeea37c40adf0eb9","value":"100%"}},"b9bdd5af51354e59a616799599671000":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcf049d12a474bfba0defdec19d0d54c","max":17684,"min":0,"orientation":"horizontal","style":"IPY_MODEL_573215ca505841c2a437b2a851d91f43","value":17684}},"430ec2b161da4e159c858b18e0dbfb90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7101bdccd7bf4299be26b8c5186c1e9c","placeholder":"​","style":"IPY_MODEL_b4a972594edc4f5da65fab5498a91f94","value":" 17684/17684 [23:55&lt;00:00, 13.00it/s]"}},"316af84f280348eb86fd9d0df10de3c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d1381143a04c2f929e6f39fb677812":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"598519dce71146d4aeea37c40adf0eb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcf049d12a474bfba0defdec19d0d54c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"573215ca505841c2a437b2a851d91f43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7101bdccd7bf4299be26b8c5186c1e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4a972594edc4f5da65fab5498a91f94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"evJiPfq4dyNh","executionInfo":{"status":"ok","timestamp":1717923738701,"user_tz":-120,"elapsed":3733,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"outputs":[],"source":["import torch\n","import h5py\n","import time\n","import pickle\n","import numpy as np\n","from tqdm.notebook import trange, tqdm\n","\n","\n","DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","source":["# Model Definition"],"metadata":{"id":"8z3QPxg8gBBK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pickle\n","\n","\n","class WolfPQEncoder(nn.Module):\n","\n","    def __init__(self, dim, M, K, min_dist_factor, semantic_sampling) -> None:\n","        super(WolfPQEncoder, self).__init__()\n","        self.dim = dim\n","        self.M = M\n","        self.K = K\n","        self.min_dist_factor = min_dist_factor\n","        self.norm = nn.LayerNorm(dim)\n","        self.layer1 = nn.Linear(dim, M * K // 2)\n","        self.layer2 = nn.Linear(M * K // 2, M * K)\n","        self.interp_param = nn.Parameter(torch.randn(1))\n","\n","\n","        self.semantic_sampling = semantic_sampling\n","\n","        if not self.semantic_sampling:\n","          self.layer1.requires_grad_(False)\n","          self.layer2.requires_grad_(False)\n","          self.interp_param.requires_grad_(False)\n","\n","\n","    def _compute_distance(self, x, codebook):\n","      \"\"\"\n","      Computes the expected quantizer indices based on the minimum distance\n","      \"\"\"\n","\n","      x_reshaped = x.reshape(x.shape[0], self.M, 1, self.dim // self.M)\n","      codebook_reshaped = codebook.reshape(1, self.M, self.K, self.dim // self.M)\n","\n","      dist = torch.sum((codebook_reshaped - x_reshaped) ** 2, dim=-1)\n","\n","      return dist\n","\n","\n","    def forward(self, x, codebook):\n","\n","        if x.shape[-1] != self.dim:\n","            raise Exception(f'Expected embedding if size {self.dim}')\n","\n","\n","        dist = self._compute_distance(x, codebook)\n","        min_dist = F.one_hot(torch.argmin(dist, dim=-1), self.K).to(dtype=torch.float)\n","\n","        if self.semantic_sampling:\n","\n","          # propoage vector throught he feed forward neural network\n","          h = F.tanh(self.layer1(self.norm(x)))\n","          a = F.relu(self.layer2(h))\n","          a_reshaped = a.reshape(-1, self.M, self.K)\n","\n","          # compute the interpolation patameter\n","          interp = F.sigmoid(self.interp_param)\n","\n","          # sample from gumbels softmax distribution based on the miniumum distance corrected by the semantic information derived from the vector\n","          # s = F.gumbel_softmax((1.0 - interp ) * a_reshaped + interp * self.min_dist_factor * min_dist, hard=True, dim=-1)\n","\n","          s = F.one_hot(torch.argmax((1.0 - interp ) * a_reshaped + interp * self.min_dist_factor * min_dist, dim=-1), num_classes=self.K)\n","\n","\n","        else:\n","\n","          # sample base don minimum distance only\n","          # s = F.gumbel_softmax(self.min_dist_factor * min_dist, hard=True, dim=-1)\n","\n","          s = F.one_hot(torch.argmax(self.min_dist_factor * min_dist, dim=-1), num_classes=self.K)\n","\n","\n","        return s\n","\n","\n","\n","class WolfPQ(nn.Module):\n","\n","    def __init__(self, dim, M, K, min_dist_factor, semantic_sampling: bool, pq_index_path: str) -> None:\n","        super(WolfPQ, self).__init__()\n","\n","        self.dim = dim\n","        self.M = M\n","        self.K = K\n","        self.min_dist_factor = min_dist_factor\n","        self.rotation_matrix = nn.Parameter(torch.stack([torch.eye(dim // M) for _ in range(M)]))\n","\n","        self.encoder = WolfPQEncoder(dim, M, K, min_dist_factor, semantic_sampling)\n","\n","        if pq_index_path == None:\n","            self.codebook = nn.Parameter(torch.randn((M, K, dim // M)))\n","\n","        else:\n","            pq_index = pickle.load(open(pq_index_path, 'rb'))\n","            initial_codebook = pq_index['codebook']\n","            self.codebook = nn.Parameter(torch.from_numpy(initial_codebook))\n","\n","\n","\n","\n","    def forward(self, x):\n","\n","        if x.shape[-1] != self.dim:\n","            raise Exception(f'Expected embedding if size {self.dim}')\n","\n","        # apply the rotational matrix to the input\n","        codebook_rot = self.codebook @ self.rotation_matrix\n","\n","        # get the indices into the codebook based on the vector\n","        s = self.encoder(x, codebook_rot)\n","\n","        # construct the quantized vector to be used during training\n","        res = codebook_rot.reshape(-1, *codebook_rot.shape) * s.reshape(*s.shape, -1)\n","        res1 = res.sum(dim=2)\n","        res2 = res1.reshape(res1.shape[0], -1)\n","\n","        return res2, s"],"metadata":{"id":"VFy57qFHf_oG","executionInfo":{"status":"ok","timestamp":1717923747745,"user_tz":-120,"elapsed":1054,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Setup the quantizer path and other parameters"],"metadata":{"id":"xbVrRUrskjol"}},{"cell_type":"code","source":["# Model parameters\n","# the path of the quantization model\n","MODEL_PATH = './drive/MyDrive/MasterThesis/final_trained_models/tct_24_1024_listwise/tct_24_1024_sem_mdf30_listwise_epoch_1.pt'\n","M=24\n","K=1024\n","MDF=30.0\n","SEMANTIC_SAMPLING=True\n","DIM=768"],"metadata":{"id":"QkZgxjnikiKd","executionInfo":{"status":"ok","timestamp":1717923753546,"user_tz":-120,"elapsed":3,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Dataset parameters\n","DATASET_PATH = './drive/MyDrive/MasterThesis/datasets/tct_colbert.h5'\n","OUTPUT_PATH = './drive/MyDrive/MasterThesis/wolfpq_indices/final_indices/wolfpq_final_tct_24_1024_sem_mdf30_listwise_epoch_1_backup.pickle'\n","BATCH_SIZE=500"],"metadata":{"id":"3puC8iQunYUy","executionInfo":{"status":"ok","timestamp":1717923755773,"user_tz":-120,"elapsed":4,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Initialize the model"],"metadata":{"id":"PQB5EA4JpIFM"}},{"cell_type":"code","source":["model = WolfPQ(DIM, M, K, MDF, semantic_sampling=SEMANTIC_SAMPLING, pq_index_path=None)\n","model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQ57vJDOpDe_","executionInfo":{"status":"ok","timestamp":1717923801259,"user_tz":-120,"elapsed":41739,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}},"outputId":"a2c5c530-e48f-4565-eeb9-72faf69b0ae1"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WolfPQ(\n","  (encoder): WolfPQEncoder(\n","    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (layer1): Linear(in_features=768, out_features=12288, bias=True)\n","    (layer2): Linear(in_features=12288, out_features=24576, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["model = model.to(DEVICE)"],"metadata":{"id":"ZKiwMmmcthou","executionInfo":{"status":"ok","timestamp":1717923816170,"user_tz":-120,"elapsed":1069,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Run the quantization process"],"metadata":{"id":"otFaLZtnrUix"}},{"cell_type":"code","source":["with h5py.File(DATASET_PATH, 'r') as dataset:\n","\n","    # load the dataset\n","    vectors = dataset['vectors']\n","    dim = vectors.shape[1]\n","\n","\n","    # COMPUTE THE Q_CODES\n","    with torch.no_grad():\n","\n","        vector_count = int(vectors.shape[0])\n","        num_batches = vector_count // BATCH_SIZE + (1 if vector_count % BATCH_SIZE > 0 else 0)\n","\n","        code_batches = []\n","\n","        for bi in trange(0, num_batches):\n","\n","\n","            index_start = bi * BATCH_SIZE\n","            index_end = min((bi + 1) * BATCH_SIZE, vector_count)\n","\n","            vector_batch = np.array(vectors[index_start:index_end, :])\n","\n","            vector_batch_torch = torch.from_numpy(vector_batch).to(DEVICE)\n","            _, code_batch_torch = model(vector_batch_torch)\n","            code_batch = torch.argmax(code_batch_torch, dim=-1).cpu().numpy()\n","\n","\n","            code_batches.append(code_batch)\n","\n","\n","\n","        q_codes = np.concatenate(code_batches, axis=0)\n","\n","\n","\n","        # GET THE CODEBOOK\n","        codebook = (model.codebook @ model.rotation_matrix).cpu().detach().numpy()\n","\n","        # BUILD THE INDEX OBJECT\n","\n","        index_obj = {\n","            'codebook': codebook,\n","            'quantized_index': q_codes,\n","            'M': M,\n","            'K': K,\n","            'vector_size': dim,\n","            'doc_ids': np.array(dataset['docids'][:])\n","        }\n","\n","\n","        # SAVE THE INDEX OBJECT\n","        pickle.dump(index_obj, open(OUTPUT_PATH, 'wb'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["bb0dc2baaa114e37bf582c89cf290544","c4aa727089994d1c8b230bd14302e895","b9bdd5af51354e59a616799599671000","430ec2b161da4e159c858b18e0dbfb90","316af84f280348eb86fd9d0df10de3c5","f5d1381143a04c2f929e6f39fb677812","598519dce71146d4aeea37c40adf0eb9","dcf049d12a474bfba0defdec19d0d54c","573215ca505841c2a437b2a851d91f43","7101bdccd7bf4299be26b8c5186c1e9c","b4a972594edc4f5da65fab5498a91f94"]},"id":"2y9jaSmapRdN","executionInfo":{"status":"ok","timestamp":1717925266432,"user_tz":-120,"elapsed":1442883,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}},"outputId":"eebbdefc-d757-4c26-9992-0488f12df882"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/17684 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb0dc2baaa114e37bf582c89cf290544"}},"metadata":{}}]},{"cell_type":"code","source":["pickle.dump(index_obj, open(OUTPUT_PATH, 'wb'))"],"metadata":{"id":"0m33kCLPsOpi","executionInfo":{"status":"ok","timestamp":1717916037311,"user_tz":-120,"elapsed":32533,"user":{"displayName":"Cătălin Lupău","userId":"02489324868434298284"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k_BZhbdrydWe"},"execution_count":null,"outputs":[]}]}